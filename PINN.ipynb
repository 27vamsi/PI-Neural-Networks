{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8GkXxSxgW9p1X46i5xRsG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/27vamsi/PI-Neural-Networks/blob/main/PINN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNMwJrcXGbnz",
        "outputId": "f79ed388-101b-4d77-a361-04f512cddf60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Initializing YOLOv8 detector with model: /content/drive/MyDrive/bestt.pt\n",
            "Installing ultralytics...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m994.1/994.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Enhanced FireSpreadPredictor initialized with ceiling lamp filtering and IOU tracking\n",
            "Processing video with enhanced prediction, ceiling lamp filtering, and IOU tracking... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 100%|██████████████████████████████████████████████████████████▉| 100%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3613 frames in 1822.3 seconds\n",
            "Output video saved to /content/drive/MyDrive/fire_prediction_with_iou.mp4\n",
            "Average IOU: 0.850\n",
            "Average Temporal IOU: 0.821\n",
            "\n",
            "--- PERFORMANCE REPORT ---\n",
            "\n",
            "Detection Metrics:\n",
            "  Total frames processed: 3613\n",
            "  Average inference time: 0.3929 seconds\n",
            "  Processing FPS: 1.98\n",
            "  Detection rate: 98.12%\n",
            "  Average confidence: 0.4068\n",
            "\n",
            "IOU Metrics:\n",
            "  Average IOU: 0.8500\n",
            "  Min IOU: 0.2755\n",
            "  Max IOU: 0.9997\n",
            "  Average Temporal IOU: 0.8215\n",
            "\n",
            "Prediction Metrics:\n",
            "  Prediction success rate: 31.67%\n",
            "  Total predictions: 722\n",
            "  Successful predictions: 228\n",
            "  Failed predictions: 492\n",
            "\n",
            "Prediction Quality:\n",
            "  Excellent: 66\n",
            "  Good: 162\n",
            "  Moderate: 211\n",
            "  Poor: 281\n",
            "\n",
            "--- END OF REPORT ---\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from scipy.linalg import block_diag\n",
        "\n",
        "class YOLOv8FireDetector:\n",
        "    def __init__(self, model_path='bestt.pt'):\n",
        "        print(f\"Initializing YOLOv8 detector with model: {model_path}\")\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
        "\n",
        "        try:\n",
        "            import ultralytics\n",
        "        except ImportError:\n",
        "            print(\"Installing ultralytics...\")\n",
        "            !pip install -q ultralytics\n",
        "            import ultralytics\n",
        "\n",
        "        from ultralytics import YOLO\n",
        "        self.model = YOLO(model_path)\n",
        "\n",
        "        self.conf_threshold = 0.05\n",
        "\n",
        "        self.model_path = model_path\n",
        "        self.model_name = os.path.basename(model_path)\n",
        "\n",
        "        self.metrics = {\n",
        "            'inference_times': [],\n",
        "            'detection_counts': [],\n",
        "            'confidence_scores': [],\n",
        "            'fire_areas': [],\n",
        "            'fire_intensities': [],\n",
        "            'iou_scores': []\n",
        "        }\n",
        "\n",
        "        self.detection_history = []\n",
        "        self.max_history_length = 10\n",
        "\n",
        "        self.prev_detections = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class', 'name'])\n",
        "\n",
        "        self.position_stability_threshold = 5\n",
        "        self.color_variance_threshold = 20\n",
        "        self.min_shape_change_threshold = 0.05\n",
        "\n",
        "        self.ceiling_filter_enabled = True\n",
        "        self.ceiling_height_threshold = 0.25\n",
        "        self.center_width_range = (0.25, 0.75)\n",
        "\n",
        "    def calculate_iou(self, box1, box2):\n",
        "        x1_inter = max(box1[0], box2[0])\n",
        "        y1_inter = max(box1[1], box2[1])\n",
        "        x2_inter = min(box1[2], box2[2])\n",
        "        y2_inter = min(box1[3], box2[3])\n",
        "\n",
        "        if x2_inter < x1_inter or y2_inter < y1_inter:\n",
        "            return 0.0\n",
        "\n",
        "        inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)\n",
        "\n",
        "        box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "        box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "\n",
        "        union_area = box1_area + box2_area - inter_area\n",
        "\n",
        "        return inter_area / union_area if union_area > 0 else 0.0\n",
        "\n",
        "    def detect(self, frame):\n",
        "        start_time = time.time()\n",
        "\n",
        "        results = self.model(frame, conf=self.conf_threshold, verbose=False)\n",
        "\n",
        "        inference_time = time.time() - start_time\n",
        "        self.metrics['inference_times'].append(inference_time)\n",
        "\n",
        "        mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)\n",
        "\n",
        "        detections = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class', 'name'])\n",
        "\n",
        "        detection_count = 0\n",
        "        confidence_scores = []\n",
        "        fire_area = 0\n",
        "        avg_intensity = 0\n",
        "\n",
        "        if len(results) > 0:\n",
        "            result = results[0]\n",
        "\n",
        "            if len(result.boxes) > 0:\n",
        "                boxes = result.boxes\n",
        "\n",
        "                if boxes.xyxy.numel() > 0:\n",
        "                    xyxy = boxes.xyxy.cpu().numpy()\n",
        "                    conf = boxes.conf.cpu().numpy()\n",
        "                    cls = boxes.cls.cpu().numpy()\n",
        "\n",
        "                    detections_list = []\n",
        "                    for i in range(len(xyxy)):\n",
        "                        x1, y1, x2, y2 = xyxy[i]\n",
        "                        detections_list.append({\n",
        "                            'xmin': x1,\n",
        "                            'ymin': y1,\n",
        "                            'xmax': x2,\n",
        "                            'ymax': y2,\n",
        "                            'confidence': conf[i],\n",
        "                            'class': cls[i],\n",
        "                            'name': result.names[int(cls[i])]\n",
        "                        })\n",
        "\n",
        "                    initial_detections = pd.DataFrame(detections_list)\n",
        "\n",
        "                    filtered_detections = self.filter_lamp_detections(frame, initial_detections)\n",
        "                    detections = filtered_detections\n",
        "\n",
        "                    detection_count = len(detections)\n",
        "                    confidence_scores = detections['confidence'].tolist()\n",
        "\n",
        "                    total_intensity = 0\n",
        "                    pixel_count = 0\n",
        "\n",
        "                    for _, detection in detections.iterrows():\n",
        "                        x1, y1, x2, y2 = int(detection['xmin']), int(detection['ymin']), int(detection['xmax']), int(detection['ymax'])\n",
        "                        area = (x2 - x1) * (y2 - y1)\n",
        "                        fire_area += area\n",
        "\n",
        "                        if x1 < frame.shape[1] and y1 < frame.shape[0] and x2 > 0 and y2 > 0:\n",
        "                            x1 = max(0, x1)\n",
        "                            y1 = max(0, y1)\n",
        "                            x2 = min(frame.shape[1], x2)\n",
        "                            y2 = min(frame.shape[0], y2)\n",
        "\n",
        "                            if len(frame.shape) == 3:\n",
        "                                fire_region = cv2.cvtColor(frame[y1:y2, x1:x2], cv2.COLOR_BGR2GRAY)\n",
        "                            else:\n",
        "                                fire_region = frame[y1:y2, x1:x2]\n",
        "\n",
        "                            if fire_region.size > 0:\n",
        "                                total_intensity += np.sum(fire_region)\n",
        "                                pixel_count += fire_region.size\n",
        "\n",
        "                            cv2.rectangle(\n",
        "                                mask,\n",
        "                                (x1, y1),\n",
        "                                (x2, y2),\n",
        "                                255,\n",
        "                                -1\n",
        "                            )\n",
        "\n",
        "                    if pixel_count > 0:\n",
        "                        avg_intensity = total_intensity / pixel_count\n",
        "\n",
        "        self.metrics['detection_counts'].append(detection_count)\n",
        "        self.metrics['confidence_scores'].extend(confidence_scores)\n",
        "        self.metrics['fire_areas'].append(fire_area)\n",
        "        self.metrics['fire_intensities'].append(avg_intensity)\n",
        "\n",
        "        if not self.prev_detections.empty and not detections.empty:\n",
        "            iou_scores = []\n",
        "            for _, curr_det in detections.iterrows():\n",
        "                curr_box = [curr_det['xmin'], curr_det['ymin'], curr_det['xmax'], curr_det['ymax']]\n",
        "                best_iou = 0\n",
        "                for _, prev_det in self.prev_detections.iterrows():\n",
        "                    prev_box = [prev_det['xmin'], prev_det['ymin'], prev_det['xmax'], prev_det['ymax']]\n",
        "                    iou = self.calculate_iou(curr_box, prev_box)\n",
        "                    best_iou = max(best_iou, iou)\n",
        "                iou_scores.append(best_iou)\n",
        "\n",
        "            if iou_scores:\n",
        "                self.metrics['iou_scores'].append(np.mean(iou_scores))\n",
        "\n",
        "        self.prev_detections = detections.copy()\n",
        "\n",
        "        return mask, detections\n",
        "\n",
        "    def filter_lamp_detections(self, frame, detections, iou_threshold=0.4):\n",
        "        if detections.empty:\n",
        "            return detections\n",
        "\n",
        "        real_fire_indices = []\n",
        "\n",
        "        for idx, detection in detections.iterrows():\n",
        "            x1, y1, x2, y2 = int(detection['xmin']), int(detection['ymin']), int(detection['xmax']), int(detection['ymax'])\n",
        "\n",
        "            if x1 >= x2 or y1 >= y2 or x1 < 0 or y1 < 0 or x2 >= frame.shape[1] or y2 >= frame.shape[0]:\n",
        "                continue\n",
        "\n",
        "            center_x = (x1 + x2) / 2\n",
        "            center_y = (y1 + y2) / 2\n",
        "\n",
        "            rel_y = center_y / frame.shape[0]\n",
        "            rel_x = center_x / frame.shape[1]\n",
        "\n",
        "            is_ceiling_lamp = False\n",
        "            if self.ceiling_filter_enabled:\n",
        "                near_ceiling = rel_y < self.ceiling_height_threshold\n",
        "                in_center = self.center_width_range[0] < rel_x < self.center_width_range[1]\n",
        "                is_ceiling_lamp = near_ceiling and in_center\n",
        "\n",
        "                is_small = (x2 - x1) * (y2 - y1) < (0.05 * frame.shape[0] * frame.shape[1])\n",
        "                if is_ceiling_lamp and is_small:\n",
        "                    continue\n",
        "\n",
        "            if not is_ceiling_lamp:\n",
        "                roi = frame[y1:y2, x1:x2]\n",
        "                color_variance = self._check_color_variance(roi)\n",
        "\n",
        "                has_fire_colors = color_variance > self.color_variance_threshold\n",
        "\n",
        "                if has_fire_colors or not near_ceiling:\n",
        "                    real_fire_indices.append(idx)\n",
        "\n",
        "        if hasattr(self, 'prev_detections') and not self.prev_detections.empty:\n",
        "            for idx, detection in detections.iterrows():\n",
        "                if idx in real_fire_indices:\n",
        "                    continue  # Already identified as fire\n",
        "\n",
        "                curr_box = [detection['xmin'], detection['ymin'], detection['xmax'], detection['ymax']]\n",
        "\n",
        "                has_temporal_match = False\n",
        "                for _, prev_det in self.prev_detections.iterrows():\n",
        "                    prev_box = [prev_det['xmin'], prev_det['ymin'], prev_det['xmax'], prev_det['ymax']]\n",
        "                    iou = self.calculate_iou(curr_box, prev_box)\n",
        "\n",
        "                    if iou >= iou_threshold:\n",
        "                        has_temporal_match = True\n",
        "                        break\n",
        "\n",
        "                if has_temporal_match and idx not in real_fire_indices:\n",
        "                    real_fire_indices.append(idx)\n",
        "\n",
        "        self.detection_history.append({\n",
        "            'frame': frame.copy() if len(self.detection_history) < 2 else None,\n",
        "            'detections': detections.copy(),\n",
        "            'timestamp': time.time()\n",
        "        })\n",
        "\n",
        "        if len(self.detection_history) > self.max_history_length:\n",
        "            self.detection_history.pop(0)\n",
        "\n",
        "        return detections.iloc[real_fire_indices].reset_index(drop=True)\n",
        "\n",
        "    def _check_color_variance(self, roi):\n",
        "        if roi is None or roi.size == 0:\n",
        "            return 0\n",
        "\n",
        "        try:\n",
        "            if roi.shape[0] == 0 or roi.shape[1] == 0:\n",
        "                return 0\n",
        "\n",
        "            hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "            h_var = np.var(hsv_roi[:,:,0])\n",
        "            s_var = np.var(hsv_roi[:,:,1])\n",
        "            v_var = np.var(hsv_roi[:,:,2])\n",
        "\n",
        "            r_var = np.var(roi[:,:,2])\n",
        "            g_var = np.var(roi[:,:,1])\n",
        "            b_var = np.var(roi[:,:,0])\n",
        "\n",
        "            r_mean = np.mean(roi[:,:,2])\n",
        "            g_mean = np.mean(roi[:,:,1])\n",
        "            b_mean = np.mean(roi[:,:,0])\n",
        "\n",
        "            red_dominance = r_mean / (g_mean + b_mean + 1e-6)\n",
        "\n",
        "            color_variance = (v_var * 0.3 + r_var * 0.3 + h_var * 0.2 + s_var * 0.1 + red_dominance * 10)\n",
        "\n",
        "            return color_variance\n",
        "        except Exception as e:\n",
        "            return 0\n",
        "\n",
        "    def _check_position_stability(self, x1, y1, x2, y2):\n",
        "        current_center_x = (x1 + x2) / 2\n",
        "        current_center_y = (y1 + y2) / 2\n",
        "\n",
        "        centers = []\n",
        "\n",
        "        for hist_item in self.detection_history[:-1]:\n",
        "            for _, hist_det in hist_item['detections'].iterrows():\n",
        "                hist_x1, hist_y1 = int(hist_det['xmin']), int(hist_det['ymin'])\n",
        "                hist_x2, hist_y2 = int(hist_det['xmax']), int(hist_det['ymax'])\n",
        "\n",
        "                hist_center_x = (hist_x1 + hist_x2) / 2\n",
        "                hist_center_y = (hist_y1 + hist_y2) / 2\n",
        "\n",
        "                center_distance = np.sqrt((current_center_x - hist_center_x)**2 +\n",
        "                                         (current_center_y - hist_center_y)**2)\n",
        "\n",
        "                if center_distance < 50:\n",
        "                    centers.append((hist_center_x, hist_center_y))\n",
        "                    break\n",
        "\n",
        "        if len(centers) < 2:\n",
        "            return False\n",
        "\n",
        "        center_x_values = [c[0] for c in centers]\n",
        "        center_y_values = [c[1] for c in centers]\n",
        "\n",
        "        x_variance = np.var(center_x_values)\n",
        "        y_variance = np.var(center_y_values)\n",
        "\n",
        "        return (x_variance < self.position_stability_threshold and\n",
        "                y_variance < self.position_stability_threshold)\n",
        "\n",
        "    def get_contour_info(self, mask):\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if not contours:\n",
        "            return None, 0, (0, 0)\n",
        "\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        area = cv2.contourArea(largest_contour)\n",
        "\n",
        "        M = cv2.moments(largest_contour)\n",
        "        if M[\"m00\"] != 0:\n",
        "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "        else:\n",
        "            cx, cy = 0, 0\n",
        "\n",
        "        return largest_contour, area, (cx, cy)\n",
        "\n",
        "    def analyze_contour_shape(self, contour):\n",
        "        if contour is None or len(contour) < 5:\n",
        "            return None, 0\n",
        "\n",
        "        try:\n",
        "            ellipse = cv2.fitEllipse(contour)\n",
        "            center, axes, angle = ellipse\n",
        "\n",
        "            angle_rad = np.deg2rad(angle)\n",
        "            direction_x = np.cos(angle_rad)\n",
        "            direction_y = np.sin(angle_rad)\n",
        "\n",
        "            major_axis, minor_axis = axes\n",
        "\n",
        "            if major_axis > 0 and minor_axis > 0 and major_axis >= minor_axis:\n",
        "                try:\n",
        "                    eccentricity = np.sqrt(max(0, 1 - (minor_axis/major_axis)**2))\n",
        "                except:\n",
        "                    eccentricity = 0\n",
        "            else:\n",
        "                eccentricity = 0\n",
        "\n",
        "            return (direction_x, direction_y), eccentricity\n",
        "        except:\n",
        "            return None, 0\n",
        "\n",
        "    def extract_intensity_gradient(self, frame, mask):\n",
        "        if len(frame.shape) == 3:\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            gray = frame.copy()\n",
        "\n",
        "        masked_frame = cv2.bitwise_and(gray, gray, mask=mask)\n",
        "\n",
        "        if np.sum(mask) <= 0:\n",
        "            return (0, 0), 0\n",
        "\n",
        "        grad_x = cv2.Sobel(masked_frame, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        grad_y = cv2.Sobel(masked_frame, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "        try:\n",
        "            avg_grad_x = np.mean(grad_x[mask > 0])\n",
        "            avg_grad_y = np.mean(grad_y[mask > 0])\n",
        "\n",
        "            magnitude = np.sqrt(avg_grad_x**2 + avg_grad_y**2)\n",
        "\n",
        "            if magnitude > 1e-6:\n",
        "                avg_grad_x /= magnitude\n",
        "                avg_grad_y /= magnitude\n",
        "            else:\n",
        "                avg_grad_x, avg_grad_y = 0, 0\n",
        "        except:\n",
        "            return (0, 0), 0\n",
        "\n",
        "        return (avg_grad_x, avg_grad_y), magnitude\n",
        "\n",
        "    def get_performance_metrics(self):\n",
        "        metrics = {}\n",
        "\n",
        "        if self.metrics['inference_times']:\n",
        "            metrics['avg_inference_time'] = np.mean(self.metrics['inference_times'])\n",
        "            metrics['min_inference_time'] = np.min(self.metrics['inference_times'])\n",
        "            metrics['max_inference_time'] = np.max(self.metrics['inference_times'])\n",
        "            metrics['fps'] = 1.0 / metrics['avg_inference_time']\n",
        "            metrics['total_frames'] = len(self.metrics['inference_times'])\n",
        "        else:\n",
        "            metrics['avg_inference_time'] = 0\n",
        "            metrics['fps'] = 0\n",
        "            metrics['total_frames'] = 0\n",
        "\n",
        "        metrics['total_detections'] = sum(self.metrics['detection_counts'])\n",
        "        if metrics['total_frames'] > 0:\n",
        "            metrics['avg_detections_per_frame'] = metrics['total_detections'] / metrics['total_frames']\n",
        "        else:\n",
        "            metrics['avg_detections_per_frame'] = 0\n",
        "\n",
        "        frames_with_detections = sum(1 for count in self.metrics['detection_counts'] if count > 0)\n",
        "        metrics['frames_with_detections'] = frames_with_detections\n",
        "        metrics['detection_rate'] = frames_with_detections / metrics['total_frames'] if metrics['total_frames'] > 0 else 0\n",
        "\n",
        "        if self.metrics['confidence_scores']:\n",
        "            metrics['avg_confidence'] = np.mean(self.metrics['confidence_scores'])\n",
        "            metrics['min_confidence'] = np.min(self.metrics['confidence_scores'])\n",
        "            metrics['max_confidence'] = np.max(self.metrics['confidence_scores'])\n",
        "        else:\n",
        "            metrics['avg_confidence'] = 0\n",
        "            metrics['min_confidence'] = 0\n",
        "            metrics['max_confidence'] = 0\n",
        "\n",
        "        if self.metrics['fire_areas']:\n",
        "            metrics['avg_fire_area'] = np.mean(self.metrics['fire_areas'])\n",
        "            metrics['max_fire_area'] = np.max(self.metrics['fire_areas'])\n",
        "\n",
        "            non_zero_areas = [area for area in self.metrics['fire_areas'] if area > 0]\n",
        "            if len(non_zero_areas) > 1:\n",
        "                growth_rates = [non_zero_areas[i] / non_zero_areas[i-1] if non_zero_areas[i-1] > 0 else 1\n",
        "                               for i in range(1, len(non_zero_areas))]\n",
        "                if growth_rates:\n",
        "                    metrics['avg_growth_rate'] = np.mean(growth_rates)\n",
        "                    metrics['max_growth_rate'] = np.max(growth_rates)\n",
        "\n",
        "        if self.metrics['iou_scores']:\n",
        "            metrics['avg_iou'] = np.mean(self.metrics['iou_scores'])\n",
        "            metrics['max_iou'] = np.max(self.metrics['iou_scores'])\n",
        "            metrics['min_iou'] = np.min(self.metrics['iou_scores'])\n",
        "\n",
        "        return metrics\n",
        "\n",
        "\n",
        "class KalmanFilter:\n",
        "    def __init__(self):\n",
        "        self.state_dim = 6\n",
        "        self.measurement_dim = 2\n",
        "\n",
        "        self.x = np.zeros((self.state_dim, 1))\n",
        "\n",
        "        self.F = np.eye(self.state_dim)\n",
        "\n",
        "        self.H = np.zeros((self.measurement_dim, self.state_dim))\n",
        "        self.H[0, 0] = 1\n",
        "        self.H[1, 1] = 1\n",
        "\n",
        "        self.Q = np.eye(self.state_dim) * 0.01\n",
        "\n",
        "        self.R = np.eye(self.measurement_dim) * 10\n",
        "\n",
        "        self.P = np.eye(self.state_dim) * 100\n",
        "\n",
        "        self.I = np.eye(self.state_dim)\n",
        "\n",
        "        self.initialized = False\n",
        "\n",
        "    def update_transition_matrix(self, dt):\n",
        "        self.F[0, 2] = dt\n",
        "        self.F[0, 4] = 0.5*dt*dt\n",
        "        self.F[1, 3] = dt\n",
        "        self.F[1, 5] = 0.5*dt*dt\n",
        "        self.F[2, 4] = dt\n",
        "        self.F[3, 5] = dt\n",
        "\n",
        "    def init(self, measurement):\n",
        "        x, y = measurement\n",
        "        self.x = np.array([[x], [y], [0], [0], [0], [0]])\n",
        "        self.initialized = True\n",
        "\n",
        "    def predict(self, dt=1.0):\n",
        "        if not self.initialized:\n",
        "            return (0, 0)\n",
        "\n",
        "        self.update_transition_matrix(dt)\n",
        "\n",
        "        self.x = np.dot(self.F, self.x)\n",
        "\n",
        "        self.P = np.dot(np.dot(self.F, self.P), self.F.T) + self.Q\n",
        "\n",
        "        return (self.x[0, 0], self.x[1, 0])\n",
        "\n",
        "    def update(self, measurement):\n",
        "        if not self.initialized:\n",
        "            self.init(measurement)\n",
        "            return\n",
        "\n",
        "        z = np.array([[measurement[0]], [measurement[1]]])\n",
        "\n",
        "        S = np.dot(np.dot(self.H, self.P), self.H.T) + self.R\n",
        "        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(S))\n",
        "\n",
        "        y = z - np.dot(self.H, self.x)\n",
        "        self.x = self.x + np.dot(K, y)\n",
        "\n",
        "        self.P = np.dot((self.I - np.dot(K, self.H)), self.P)\n",
        "\n",
        "    def get_state(self):\n",
        "        if not self.initialized:\n",
        "            return (0, 0), (0, 0), (0, 0)\n",
        "\n",
        "        pos = (self.x[0, 0], self.x[1, 0])\n",
        "        vel = (self.x[2, 0], self.x[3, 0])\n",
        "        acc = (self.x[4, 0], self.x[5, 0])\n",
        "\n",
        "        return pos, vel, acc\n",
        "\n",
        "    def predict_future(self, steps_ahead):\n",
        "        if not self.initialized:\n",
        "            return [(0, 0)] * steps_ahead\n",
        "\n",
        "        predictions = []\n",
        "        current_state = self.x.copy()\n",
        "        current_transition = self.F.copy()\n",
        "\n",
        "        for i in range(steps_ahead):\n",
        "            current_state = np.dot(current_transition, current_state)\n",
        "            predictions.append((current_state[0, 0], current_state[1, 0]))\n",
        "\n",
        "        return predictions\n",
        "\n",
        "\n",
        "class FireSpreadPredictor:\n",
        "    def __init__(self, yolo_model_path='bestt.pt', history_size=5, prediction_window=10):\n",
        "        self.history_size = history_size\n",
        "        self.prediction_window = prediction_window\n",
        "        self.position_history = []\n",
        "        self.area_history = []\n",
        "        self.contour_history = []\n",
        "        self.detections_history = []\n",
        "        self.intensity_history = []\n",
        "        self.shape_history = []\n",
        "        self.gradient_history = []\n",
        "        self.iou_history = []  # Added for IOU tracking\n",
        "\n",
        "        self.feature_weights = {\n",
        "            'position': 0.4,\n",
        "            'shape': 0.2,\n",
        "            'intensity': 0.2,\n",
        "            'gradient': 0.2\n",
        "        }\n",
        "\n",
        "        self.dt = 1.0\n",
        "        self.last_frame_time = None\n",
        "\n",
        "        self.kalman = KalmanFilter()\n",
        "\n",
        "        self.predictions = []\n",
        "        self.prediction_results = []\n",
        "        self.prediction_stats = {\n",
        "            'total_predictions': 0,\n",
        "            'successful_predictions': 0,\n",
        "            'failed_predictions': 0,\n",
        "            'success_rate': 0.0,\n",
        "            'prediction_errors': [],\n",
        "            'thresholds_used': []\n",
        "        }\n",
        "\n",
        "        self.quality_categories = {\n",
        "            'excellent': 0,\n",
        "            'good': 0,\n",
        "            'moderate': 0,\n",
        "            'poor': 0\n",
        "        }\n",
        "\n",
        "        self.fire_detector = YOLOv8FireDetector(model_path=yolo_model_path)\n",
        "        self.previous_detections = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class', 'name'])\n",
        "        print(\"Enhanced FireSpreadPredictor initialized with ceiling lamp filtering and IOU tracking\")\n",
        "\n",
        "    def track_detections_with_iou(self, current_detections, previous_detections, iou_threshold=0.3):\n",
        "        if previous_detections.empty or current_detections.empty:\n",
        "            return []\n",
        "\n",
        "        matches = []\n",
        "\n",
        "        for curr_idx, curr_det in current_detections.iterrows():\n",
        "            curr_box = [curr_det['xmin'], curr_det['ymin'], curr_det['xmax'], curr_det['ymax']]\n",
        "            best_iou = 0\n",
        "            best_match = -1\n",
        "\n",
        "            for prev_idx, prev_det in previous_detections.iterrows():\n",
        "                prev_box = [prev_det['xmin'], prev_det['ymin'], prev_det['xmax'], prev_det['ymax']]\n",
        "                iou = self.fire_detector.calculate_iou(curr_box, prev_box)\n",
        "\n",
        "                if iou > best_iou and iou >= iou_threshold:\n",
        "                    best_iou = iou\n",
        "                    best_match = prev_idx\n",
        "\n",
        "            if best_match != -1:\n",
        "                matches.append((curr_idx, best_match, best_iou))\n",
        "\n",
        "        return matches\n",
        "\n",
        "    def update_kalman_with_best_match(self, iou_matches, current_detections, previous_detections):\n",
        "        if not iou_matches:\n",
        "            return\n",
        "\n",
        "        sorted_matches = sorted(iou_matches, key=lambda x: x[2], reverse=True)\n",
        "        best_match = sorted_matches[0]\n",
        "\n",
        "        curr_idx = best_match[0]\n",
        "        curr_det = current_detections.iloc[curr_idx]\n",
        "\n",
        "        center_x = (curr_det['xmin'] + curr_det['xmax']) / 2\n",
        "        center_y = (curr_det['ymin'] + curr_det['ymax']) / 2\n",
        "\n",
        "        self.kalman.update((center_x, center_y))\n",
        "\n",
        "    def add_frame(self, frame, frame_index, timestamp=None):\n",
        "        if timestamp is not None:\n",
        "            if self.last_frame_time is not None:\n",
        "                self.dt = timestamp - self.last_frame_time\n",
        "            self.last_frame_time = timestamp\n",
        "\n",
        "        mask, detections = self.fire_detector.detect(frame)\n",
        "        contour, area, centroid = self.fire_detector.get_contour_info(mask)\n",
        "\n",
        "        shape_direction, shape_confidence = (0, 0), 0\n",
        "        if contour is not None:\n",
        "            shape_direction, shape_confidence = self.fire_detector.analyze_contour_shape(contour)\n",
        "\n",
        "        gradient_direction, gradient_magnitude = self.fire_detector.extract_intensity_gradient(frame, mask)\n",
        "\n",
        "        # Track detections using IOU\n",
        "        iou_matches = []\n",
        "        if not self.previous_detections.empty and not detections.empty:\n",
        "            iou_matches = self.track_detections_with_iou(detections, self.previous_detections)\n",
        "\n",
        "            # Store IOU scores in history\n",
        "            avg_iou = np.mean([match[2] for match in iou_matches]) if iou_matches else 0\n",
        "            self.iou_history.append(avg_iou)\n",
        "\n",
        "            # Keep history limited\n",
        "            if len(self.iou_history) > self.history_size:\n",
        "                self.iou_history.pop(0)\n",
        "\n",
        "            # Use IOU for better Kalman updates\n",
        "            if iou_matches:\n",
        "                self.update_kalman_with_best_match(iou_matches, detections, self.previous_detections)\n",
        "\n",
        "        # Store current detections for next frame\n",
        "        self.previous_detections = detections.copy()\n",
        "\n",
        "        self.kalman.update(centroid)\n",
        "\n",
        "        self.position_history.append(centroid)\n",
        "        self.area_history.append(area)\n",
        "        self.contour_history.append(contour if contour is not None else None)\n",
        "        self.detections_history.append(detections)\n",
        "        self.shape_history.append((shape_direction, shape_confidence))\n",
        "        self.gradient_history.append((gradient_direction, gradient_magnitude))\n",
        "\n",
        "        if len(self.position_history) > self.history_size:\n",
        "            self.position_history.pop(0)\n",
        "            self.area_history.pop(0)\n",
        "            self.contour_history.pop(0)\n",
        "            self.detections_history.pop(0)\n",
        "            self.shape_history.pop(0)\n",
        "            self.gradient_history.pop(0)\n",
        "\n",
        "        if frame_index % 5 == 0 and len(self.position_history) >= 2:\n",
        "            self._make_prediction(frame_index, centroid, area)\n",
        "\n",
        "        self._evaluate_predictions(frame_index, centroid, area)\n",
        "\n",
        "        return mask, detections\n",
        "\n",
        "    def _make_prediction(self, frame_index, current_position, current_area):\n",
        "        kalman_prediction = self.kalman.predict_future(self.prediction_window)[-1] if self.kalman.initialized else current_position\n",
        "\n",
        "        linear_direction, growth_factor = self.predict_direction()\n",
        "\n",
        "        linear_prediction = current_position\n",
        "        if len(self.position_history) >= 2:\n",
        "            oldest_pos = self.position_history[0]\n",
        "            newest_pos = self.position_history[-1]\n",
        "            dx = newest_pos[0] - oldest_pos[0]\n",
        "            dy = newest_pos[1] - oldest_pos[1]\n",
        "            steps_taken = len(self.position_history) - 1\n",
        "\n",
        "            step_x = dx / steps_taken if steps_taken > 0 else 0\n",
        "            step_y = dy / steps_taken if steps_taken > 0 else 0\n",
        "\n",
        "            linear_x = current_position[0] + (step_x * self.prediction_window)\n",
        "            linear_y = current_position[1] + (step_y * self.prediction_window)\n",
        "            linear_prediction = (int(linear_x), int(linear_y))\n",
        "\n",
        "        shape_prediction = current_position\n",
        "        if self.shape_history and self.shape_history[-1][0] is not None:\n",
        "            direction, confidence = self.shape_history[-1]\n",
        "            shape_x = current_position[0] + direction[0] * confidence * self.prediction_window * 10\n",
        "            shape_y = current_position[1] + direction[1] * confidence * self.prediction_window * 10\n",
        "            shape_prediction = (int(shape_x), int(shape_y))\n",
        "\n",
        "        gradient_prediction = current_position\n",
        "        if self.gradient_history and self.gradient_history[-1][0] is not None:\n",
        "            direction, magnitude = self.gradient_history[-1]\n",
        "            gradient_x = current_position[0] + direction[0] * magnitude * self.prediction_window * 0.5\n",
        "            gradient_y = current_position[1] + direction[1] * magnitude * self.prediction_window * 0.5\n",
        "            gradient_prediction = (int(gradient_x), int(gradient_y))\n",
        "\n",
        "        weights = self.feature_weights\n",
        "        final_x = (weights['position'] * kalman_prediction[0] +\n",
        "                  weights['shape'] * shape_prediction[0] +\n",
        "                  weights['intensity'] * linear_prediction[0] +\n",
        "                  weights['gradient'] * gradient_prediction[0])\n",
        "\n",
        "        final_y = (weights['position'] * kalman_prediction[1] +\n",
        "                  weights['shape'] * shape_prediction[1] +\n",
        "                  weights['intensity'] * linear_prediction[1] +\n",
        "                  weights['gradient'] * gradient_prediction[1])\n",
        "\n",
        "        final_prediction = (int(final_x), int(final_y))\n",
        "\n",
        "        prediction = {\n",
        "            'frame_index': frame_index,\n",
        "            'current_position': current_position,\n",
        "            'current_area': current_area,\n",
        "            'predicted_position': final_prediction,\n",
        "            'kalman_prediction': kalman_prediction,\n",
        "            'linear_prediction': linear_prediction,\n",
        "            'shape_prediction': shape_prediction,\n",
        "            'gradient_prediction': gradient_prediction,\n",
        "            'evaluation_frame': frame_index + self.prediction_window,\n",
        "            'evaluated': False\n",
        "        }\n",
        "\n",
        "        self.predictions.append(prediction)\n",
        "        self.prediction_stats['total_predictions'] += 1\n",
        "\n",
        "    def _calculate_dynamic_threshold(self, fire_area):\n",
        "        if fire_area <= 0:\n",
        "            return 50\n",
        "\n",
        "        fire_width = np.sqrt(fire_area)\n",
        "        threshold = max(30, min(200, fire_width * 0.1))\n",
        "        return threshold\n",
        "\n",
        "    def _evaluate_predictions(self, current_frame_index, current_position, current_area):\n",
        "        for prediction in self.predictions:\n",
        "            if not prediction['evaluated'] and current_frame_index >= prediction['evaluation_frame']:\n",
        "                pred_x, pred_y = prediction['predicted_position']\n",
        "                actual_x, actual_y = current_position\n",
        "\n",
        "                distance_error = np.sqrt((pred_x - actual_x)**2 + (pred_y - actual_y)**2)\n",
        "\n",
        "                fire_area = prediction['current_area']\n",
        "                success_threshold = self._calculate_dynamic_threshold(fire_area)\n",
        "\n",
        "                self.prediction_stats['thresholds_used'].append(success_threshold)\n",
        "\n",
        "                success = distance_error <= success_threshold\n",
        "\n",
        "                if distance_error <= success_threshold * 0.5:\n",
        "                    quality = 'excellent'\n",
        "                elif distance_error <= success_threshold:\n",
        "                    quality = 'good'\n",
        "                elif distance_error <= success_threshold * 1.5:\n",
        "                    quality = 'moderate'\n",
        "                else:\n",
        "                    quality = 'poor'\n",
        "\n",
        "                self.quality_categories[quality] += 1\n",
        "\n",
        "                prediction['evaluated'] = True\n",
        "                prediction['actual_position'] = current_position\n",
        "                prediction['distance_error'] = distance_error\n",
        "                prediction['success_threshold'] = success_threshold\n",
        "                prediction['success'] = success\n",
        "                prediction['quality'] = quality\n",
        "\n",
        "                self.prediction_stats['prediction_errors'].append(distance_error)\n",
        "                if success:\n",
        "                    self.prediction_stats['successful_predictions'] += 1\n",
        "                else:\n",
        "                    self.prediction_stats['failed_predictions'] += 1\n",
        "\n",
        "                total = self.prediction_stats['successful_predictions'] + self.prediction_stats['failed_predictions']\n",
        "                if total > 0:\n",
        "                    self.prediction_stats['success_rate'] = self.prediction_stats['successful_predictions'] / total\n",
        "\n",
        "                self.prediction_results.append(prediction)\n",
        "\n",
        "    def predict_direction(self):\n",
        "        if len(self.position_history) < 2:\n",
        "            return (0, 0), 1.0\n",
        "\n",
        "        oldest_pos = self.position_history[0]\n",
        "        newest_pos = self.position_history[-1]\n",
        "\n",
        "        dx = newest_pos[0] - oldest_pos[0]\n",
        "        dy = newest_pos[1] - oldest_pos[1]\n",
        "\n",
        "        magnitude = np.sqrt(dx**2 + dy**2)\n",
        "\n",
        "        if magnitude > 1e-6:\n",
        "            dx, dy = dx/magnitude, dy/magnitude\n",
        "        else:\n",
        "            dx, dy = 0, 1\n",
        "\n",
        "        if self.area_history[0] > 0:\n",
        "            growth_factor = self.area_history[-1] / self.area_history[0]\n",
        "        else:\n",
        "            growth_factor = 1.2\n",
        "\n",
        "        return (dx, dy), growth_factor\n",
        "\n",
        "    def create_danger_zone(self, frame, prediction_distance=50, frame_index=None):\n",
        "        if not self.contour_history or self.contour_history[-1] is None:\n",
        "            return frame.copy(), np.zeros_like(frame[:,:,0])\n",
        "\n",
        "        latest_contour = self.contour_history[-1]\n",
        "        latest_center = self.position_history[-1]\n",
        "        latest_detections = self.detections_history[-1]\n",
        "\n",
        "        latest_area = self.area_history[-1] if self.area_history else 0\n",
        "        dynamic_threshold = self._calculate_dynamic_threshold(latest_area)\n",
        "\n",
        "        kalman_pos, kalman_vel, _ = self.kalman.get_state()\n",
        "\n",
        "        vel_magnitude = np.sqrt(kalman_vel[0]**2 + kalman_vel[1]**2)\n",
        "        if vel_magnitude > 1e-6:\n",
        "            kalman_dx, kalman_dy = kalman_vel[0]/vel_magnitude, kalman_vel[1]/vel_magnitude\n",
        "        else:\n",
        "            kalman_dx, kalman_dy = 0, 0\n",
        "\n",
        "        visualization = frame.copy()\n",
        "\n",
        "        for _, detection in latest_detections.iterrows():\n",
        "            x1, y1, x2, y2 = int(detection['xmin']), int(detection['ymin']), int(detection['xmax']), int(detection['ymax'])\n",
        "            conf = detection['confidence']\n",
        "\n",
        "            cv2.rectangle(visualization, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "        if latest_contour is not None:\n",
        "            cv2.drawContours(visualization, [latest_contour], -1, (0, 0, 255), 2)\n",
        "\n",
        "        danger_mask = np.zeros_like(frame[:,:,0])\n",
        "\n",
        "        kalman_predictions = self.kalman.predict_future(int(prediction_distance/5))\n",
        "\n",
        "        prev_point = latest_center\n",
        "        for i, point in enumerate(kalman_predictions):\n",
        "            point = (int(point[0]), int(point[1]))\n",
        "            cv2.line(visualization, prev_point, point, (255, 0, 0), 1 + i//3)\n",
        "            prev_point = point\n",
        "\n",
        "        linear_direction, growth_factor = self.predict_direction()\n",
        "        shape_direction, shape_confidence = self.shape_history[-1] if self.shape_history else ((0,0), 0)\n",
        "        gradient_direction, gradient_magnitude = self.gradient_history[-1] if self.gradient_history else ((0,0), 0)\n",
        "\n",
        "        weights = self.feature_weights\n",
        "\n",
        "        shape_dir_x = shape_direction[0] if shape_direction else 0\n",
        "        shape_dir_y = shape_direction[1] if shape_direction else 0\n",
        "        gradient_dir_x = gradient_direction[0] if gradient_direction else 0\n",
        "        gradient_dir_y = gradient_direction[1] if gradient_direction else 0\n",
        "\n",
        "        combined_dx = (weights['position'] * kalman_dx +\n",
        "                      weights['shape'] * shape_dir_x +\n",
        "                      weights['gradient'] * gradient_dir_x +\n",
        "                      weights['intensity'] * linear_direction[0])\n",
        "\n",
        "        combined_dy = (weights['position'] * kalman_dy +\n",
        "                      weights['shape'] * shape_dir_y +\n",
        "                      weights['gradient'] * gradient_dir_y +\n",
        "                      weights['intensity'] * linear_direction[1])\n",
        "\n",
        "        magnitude = np.sqrt(combined_dx**2 + combined_dy**2)\n",
        "        if magnitude > 1e-6:\n",
        "            combined_dx, combined_dy = combined_dx/magnitude, combined_dy/magnitude\n",
        "        else:\n",
        "            combined_dx, combined_dy = 0, 1\n",
        "\n",
        "        danger_endpoint = (\n",
        "            int(latest_center[0] + combined_dx * prediction_distance),\n",
        "            int(latest_center[1] + combined_dy * prediction_distance)\n",
        "        )\n",
        "\n",
        "        angle = np.arctan2(combined_dy, combined_dx)\n",
        "        base_width = np.sqrt(max(1, self.area_history[-1]) / np.pi) * growth_factor * 0.8\n",
        "\n",
        "        p1 = latest_center\n",
        "        p2 = (\n",
        "            int(latest_center[0] + base_width * np.cos(angle + np.pi/2)),\n",
        "            int(latest_center[1] + base_width * np.sin(angle + np.pi/2))\n",
        "        )\n",
        "        p3 = danger_endpoint\n",
        "        p4 = (\n",
        "            int(latest_center[0] + base_width * np.cos(angle - np.pi/2)),\n",
        "            int(latest_center[1] + base_width * np.sin(angle - np.pi/2))\n",
        "        )\n",
        "\n",
        "        danger_zone_points = np.array([p1, p2, p3, p4], np.int32)\n",
        "        danger_zone_points = danger_zone_points.reshape((-1, 1, 2))\n",
        "        cv2.fillPoly(danger_mask, [danger_zone_points], 255)\n",
        "\n",
        "        danger_overlay = visualization.copy()\n",
        "        danger_overlay[danger_mask > 0] = (0, 255, 0)\n",
        "        visualization = cv2.addWeighted(visualization, 0.7, danger_overlay, 0.3, 0)\n",
        "\n",
        "        cv2.arrowedLine(\n",
        "            visualization,\n",
        "            latest_center,\n",
        "            danger_endpoint,\n",
        "            (0, 255, 0),\n",
        "            3\n",
        "        )\n",
        "\n",
        "        if frame_index is not None:\n",
        "            for prediction in self.predictions:\n",
        "                if prediction['evaluation_frame'] == frame_index:\n",
        "                    cv2.circle(\n",
        "                        visualization,\n",
        "                        prediction['predicted_position'],\n",
        "                        10,\n",
        "                        (0, 255, 255),\n",
        "                        -1\n",
        "                    )\n",
        "\n",
        "                    try:\n",
        "                        kalman_x = int(prediction['kalman_prediction'][0])\n",
        "                        kalman_y = int(prediction['kalman_prediction'][1])\n",
        "                        cv2.circle(\n",
        "                            visualization,\n",
        "                            (kalman_x, kalman_y),\n",
        "                            8,\n",
        "                            (255, 0, 0),\n",
        "                            -1\n",
        "                        )\n",
        "                    except (TypeError, ValueError):\n",
        "                        pass\n",
        "\n",
        "                    cv2.putText(\n",
        "                        visualization,\n",
        "                        f\"Predicted Position\",\n",
        "                        (prediction['predicted_position'][0] + 10, prediction['predicted_position'][1]),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.7,\n",
        "                        (0, 255, 255),\n",
        "                        2\n",
        "                    )\n",
        "\n",
        "                    if 'success_threshold' in prediction:\n",
        "                        cv2.circle(\n",
        "                            visualization,\n",
        "                            prediction['predicted_position'],\n",
        "                            int(prediction['success_threshold']),\n",
        "                            (255, 255, 0),\n",
        "                            1\n",
        "                        )\n",
        "\n",
        "            if self.prediction_stats['total_predictions'] > 0:\n",
        "                success_text = f\"Prediction Accuracy: {self.prediction_stats['success_rate']*100:.1f}% ({self.prediction_stats['successful_predictions']}/{self.prediction_stats['total_predictions']})\"\n",
        "                cv2.putText(\n",
        "                    visualization,\n",
        "                    success_text,\n",
        "                    (20, 30),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.7,\n",
        "                    (255, 255, 255),\n",
        "                    2\n",
        "                )\n",
        "\n",
        "                if self.prediction_stats['thresholds_used']:\n",
        "                    threshold_text = f\"Dynamic Threshold: {self.prediction_stats['thresholds_used'][-1]:.1f} px\"\n",
        "                    cv2.putText(\n",
        "                        visualization,\n",
        "                        threshold_text,\n",
        "                        (20, 60),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.7,\n",
        "                        (255, 255, 255),\n",
        "                        2\n",
        "                    )\n",
        "\n",
        "            # Display average IOU if available\n",
        "            if self.iou_history:\n",
        "                iou_text = f\"Avg IOU: {self.iou_history[-1]:.2f}\"\n",
        "                cv2.putText(\n",
        "                    visualization,\n",
        "                    iou_text,\n",
        "                    (20, 90),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.7,\n",
        "                    (255, 255, 255),\n",
        "                    2\n",
        "                )\n",
        "\n",
        "            cv2.putText(\n",
        "                visualization,\n",
        "                \"Ceiling Lamp Filter: ACTIVE\",\n",
        "                (visualization.shape[1] - 280, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.7,\n",
        "                (255, 255, 255),\n",
        "                2\n",
        "            )\n",
        "\n",
        "            # Add IOU tracking status\n",
        "            cv2.putText(\n",
        "                visualization,\n",
        "                \"IOU Tracking: ACTIVE\",\n",
        "                (visualization.shape[1] - 280, 60),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.7,\n",
        "                (255, 255, 255),\n",
        "                2\n",
        "            )\n",
        "\n",
        "        return visualization, danger_mask\n",
        "\n",
        "    def get_performance_metrics(self):\n",
        "        metrics = self.fire_detector.get_performance_metrics()\n",
        "\n",
        "        metrics.update({\n",
        "            'total_predictions': self.prediction_stats['total_predictions'],\n",
        "            'successful_predictions': self.prediction_stats['successful_predictions'],\n",
        "            'failed_predictions': self.prediction_stats['failed_predictions'],\n",
        "            'prediction_success_rate': self.prediction_stats['success_rate'],\n",
        "        })\n",
        "\n",
        "        if self.prediction_stats['prediction_errors']:\n",
        "            metrics['avg_prediction_error'] = np.mean(self.prediction_stats['prediction_errors'])\n",
        "            metrics['max_prediction_error'] = np.max(self.prediction_stats['prediction_errors'])\n",
        "            metrics['min_prediction_error'] = np.min(self.prediction_stats['prediction_errors'])\n",
        "\n",
        "        if self.prediction_stats['thresholds_used']:\n",
        "            metrics['avg_threshold'] = np.mean(self.prediction_stats['thresholds_used'])\n",
        "            metrics['min_threshold'] = np.min(self.prediction_stats['thresholds_used'])\n",
        "            metrics['max_threshold'] = np.max(self.prediction_stats['thresholds_used'])\n",
        "\n",
        "        if self.iou_history:\n",
        "            metrics['avg_temporal_iou'] = np.mean(self.iou_history)\n",
        "            metrics['max_temporal_iou'] = np.max(self.iou_history) if self.iou_history else 0\n",
        "            metrics['min_temporal_iou'] = np.min(self.iou_history) if self.iou_history else 0\n",
        "\n",
        "        metrics.update(self.quality_categories)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "\n",
        "def process_video(video_path, output_path='tata.mp4', model_path='bestt.pt', window_size=5, prediction_window=10):\n",
        "    output_dir = \"fire_predictions_enhanced\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Failed to open video file: {video_path}\")\n",
        "        print(f\"File exists: {os.path.exists(video_path)}\")\n",
        "        if os.path.exists(video_path):\n",
        "            print(f\"File size: {os.path.getsize(video_path)} bytes\")\n",
        "            print(f\"File permissions: {oct(os.stat(video_path).st_mode)}\")\n",
        "        raise IOError(f\"Error: Could not open video {video_path}\")\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    predictor = FireSpreadPredictor(\n",
        "        yolo_model_path=model_path,\n",
        "        history_size=window_size,\n",
        "        prediction_window=prediction_window\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Processing video with enhanced prediction, ceiling lamp filtering, and IOU tracking... \")\n",
        "\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "    with tqdm(total=total_frames, desc=\"Progress\", unit=\"%\", bar_format='{l_bar}{bar}| {percentage:3.0f}%', ncols=80) as pbar:\n",
        "        frame_idx = 0\n",
        "\n",
        "        for _ in range(min(window_size, total_frames)):\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            timestamp = frame_idx / fps if fps > 0 else frame_idx\n",
        "            predictor.add_frame(frame, frame_idx, timestamp)\n",
        "            frame_idx += 1\n",
        "            pbar.update(1)\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            timestamp = frame_idx / fps if fps > 0 else frame_idx\n",
        "            mask, _ = predictor.add_frame(frame, frame_idx, timestamp)\n",
        "\n",
        "            prediction_distance = width * 0.15\n",
        "            visualization, _ = predictor.create_danger_zone(frame, prediction_distance, frame_idx)\n",
        "\n",
        "            out.write(visualization)\n",
        "\n",
        "            frame_idx += 1\n",
        "            if frame_idx % 5 == 0:\n",
        "                pbar.update(5)\n",
        "\n",
        "            if frame_idx % 30 == 0:\n",
        "                gc.collect()\n",
        "                torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    metrics = predictor.get_performance_metrics()\n",
        "    metrics['processing_time'] = total_time\n",
        "    metrics['processing_fps'] = total_frames / total_time\n",
        "\n",
        "    # Create report\n",
        "    print(f\"Processed {total_frames} frames in {total_time:.1f} seconds\")\n",
        "    print(f\"Output video saved to {output_path}\")\n",
        "\n",
        "    # Print IOU metrics\n",
        "    if 'avg_iou' in metrics:\n",
        "        print(f\"Average IOU: {metrics['avg_iou']:.3f}\")\n",
        "    if 'avg_temporal_iou' in metrics:\n",
        "        print(f\"Average Temporal IOU: {metrics['avg_temporal_iou']:.3f}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def create_performance_report(metrics):\n",
        "    \"\"\"Create a performance report with metrics including IOU metrics.\"\"\"\n",
        "    print(\"\\n--- PERFORMANCE REPORT ---\\n\")\n",
        "\n",
        "    print(\"Detection Metrics:\")\n",
        "    print(f\"  Total frames processed: {metrics.get('total_frames', 0)}\")\n",
        "    print(f\"  Average inference time: {metrics.get('avg_inference_time', 0):.4f} seconds\")\n",
        "    print(f\"  Processing FPS: {metrics.get('processing_fps', 0):.2f}\")\n",
        "    print(f\"  Detection rate: {metrics.get('detection_rate', 0)*100:.2f}%\")\n",
        "\n",
        "    print(\"\\nIOU Metrics:\")\n",
        "    print(f\"  Average IOU: {metrics.get('avg_iou', 0):.4f}\")\n",
        "    print(f\"  Min IOU: {metrics.get('min_iou', 0):.4f}\")\n",
        "    print(f\"  Max IOU: {metrics.get('max_iou', 0):.4f}\")\n",
        "    print(f\"  Average Temporal IOU: {metrics.get('avg_temporal_iou', 0):.4f}\")\n",
        "\n",
        "\n",
        "    print(\"\\n--- END OF REPORT ---\\n\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Mount Google Drive if in Colab\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "            in_colab = True\n",
        "        except:\n",
        "            in_colab = False\n",
        "\n",
        "        # Set paths\n",
        "        if in_colab:\n",
        "            model_path = '/content/drive/MyDrive/bestt.pt'\n",
        "            video_path = '/content/drive/MyDrive/fire.mp4'\n",
        "            output_path = '/content/drive/MyDrive/fire_prediction_with_iou.mp4'\n",
        "        else:\n",
        "            model_path = 'bestt.pt'\n",
        "            video_path = 'fire.mp4'\n",
        "            output_path = 'fire_prediction_with_iou.mp4'\n",
        "\n",
        "        # Process video and generate metrics with enhanced prediction and IOU tracking\n",
        "        metrics = process_video(\n",
        "            video_path=video_path,\n",
        "            output_path=output_path,\n",
        "            model_path=model_path,\n",
        "            window_size=5,\n",
        "            prediction_window=10\n",
        "        )\n",
        "\n",
        "        # Create report with new IOU metrics\n",
        "        create_performance_report(metrics)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ]
    }
  ]
}